{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,200,842\n",
      "Trainable params: 4,200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 1.7580 - accuracy: 0.3872 - val_loss: 1.4051 - val_accuracy: 0.5053\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 1.3910 - accuracy: 0.5076 - val_loss: 1.2919 - val_accuracy: 0.5452\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 1.2681 - accuracy: 0.5524 - val_loss: 1.1864 - val_accuracy: 0.5913\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 1.1834 - accuracy: 0.5803 - val_loss: 1.2293 - val_accuracy: 0.5674\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 1.1216 - accuracy: 0.6049 - val_loss: 1.1047 - val_accuracy: 0.6110\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 1.0559 - accuracy: 0.6318 - val_loss: 1.0977 - val_accuracy: 0.6224\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 53s 1ms/step - loss: 1.0096 - accuracy: 0.6467 - val_loss: 1.0467 - val_accuracy: 0.6411\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 53s 1ms/step - loss: 0.9666 - accuracy: 0.6641 - val_loss: 1.1389 - val_accuracy: 0.6107\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 65s 2ms/step - loss: 0.9250 - accuracy: 0.6777 - val_loss: 1.0422 - val_accuracy: 0.6421\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 65s 2ms/step - loss: 0.8850 - accuracy: 0.6934 - val_loss: 1.0454 - val_accuracy: 0.6430\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.8519 - accuracy: 0.7008 - val_loss: 1.0335 - val_accuracy: 0.6566\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 67s 2ms/step - loss: 0.8223 - accuracy: 0.7142 - val_loss: 1.0180 - val_accuracy: 0.6606\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 67s 2ms/step - loss: 0.7951 - accuracy: 0.7215 - val_loss: 1.0097 - val_accuracy: 0.6638\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.7699 - accuracy: 0.7332 - val_loss: 1.0247 - val_accuracy: 0.6638\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 56s 1ms/step - loss: 0.7421 - accuracy: 0.7428 - val_loss: 1.0705 - val_accuracy: 0.6584\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 55s 1ms/step - loss: 0.7138 - accuracy: 0.7544 - val_loss: 1.1224 - val_accuracy: 0.6467\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 55s 1ms/step - loss: 0.6897 - accuracy: 0.7604 - val_loss: 1.1448 - val_accuracy: 0.6466\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.6660 - accuracy: 0.7678 - val_loss: 1.0212 - val_accuracy: 0.6750\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 79s 2ms/step - loss: 0.6466 - accuracy: 0.7750 - val_loss: 1.0442 - val_accuracy: 0.6788\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 84s 2ms/step - loss: 0.6293 - accuracy: 0.7839 - val_loss: 1.0437 - val_accuracy: 0.6773\n",
      "10000/10000 [==============================] - 8s 803us/step\n",
      "Test score: 1.0577401285171508\n",
      "Test accuracy: 0.6690999865531921\n"
     ]
    }
   ],
   "source": [
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "# And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,676,842\n",
      "Trainable params: 1,676,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "40000/40000 [==============================] - 151s 4ms/step - loss: 1.8140 - accuracy: 0.3458 - val_loss: 1.4621 - val_accuracy: 0.4725\n",
      "Epoch 2/40\n",
      "40000/40000 [==============================] - 150s 4ms/step - loss: 1.3475 - accuracy: 0.5171 - val_loss: 1.1078 - val_accuracy: 0.6042\n",
      "Epoch 3/40\n",
      "40000/40000 [==============================] - 148s 4ms/step - loss: 1.1407 - accuracy: 0.5985 - val_loss: 0.9816 - val_accuracy: 0.6598\n",
      "Epoch 4/40\n",
      "40000/40000 [==============================] - 156s 4ms/step - loss: 1.0055 - accuracy: 0.6472 - val_loss: 0.9943 - val_accuracy: 0.6443\n",
      "Epoch 5/40\n",
      "40000/40000 [==============================] - 147s 4ms/step - loss: 0.9060 - accuracy: 0.6829 - val_loss: 0.8796 - val_accuracy: 0.6898\n",
      "Epoch 6/40\n",
      "40000/40000 [==============================] - 148s 4ms/step - loss: 0.8372 - accuracy: 0.7079 - val_loss: 0.8408 - val_accuracy: 0.7030\n",
      "Epoch 7/40\n",
      "40000/40000 [==============================] - 149s 4ms/step - loss: 0.7765 - accuracy: 0.7320 - val_loss: 0.8209 - val_accuracy: 0.7174\n",
      "Epoch 8/40\n",
      "40000/40000 [==============================] - 97s 2ms/step - loss: 0.7320 - accuracy: 0.7441 - val_loss: 0.7324 - val_accuracy: 0.7473\n",
      "Epoch 9/40\n",
      "40000/40000 [==============================] - 95s 2ms/step - loss: 0.6877 - accuracy: 0.7602 - val_loss: 0.7856 - val_accuracy: 0.7376\n",
      "Epoch 10/40\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.6611 - accuracy: 0.7699 - val_loss: 0.7066 - val_accuracy: 0.7598\n",
      "Epoch 11/40\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.6307 - accuracy: 0.7816 - val_loss: 0.7774 - val_accuracy: 0.7478\n",
      "Epoch 12/40\n",
      "40000/40000 [==============================] - 129s 3ms/step - loss: 0.6203 - accuracy: 0.7867 - val_loss: 0.7365 - val_accuracy: 0.7527\n",
      "Epoch 13/40\n",
      "40000/40000 [==============================] - 147s 4ms/step - loss: 0.5995 - accuracy: 0.7943 - val_loss: 0.7795 - val_accuracy: 0.7560\n",
      "Epoch 14/40\n",
      "40000/40000 [==============================] - 147s 4ms/step - loss: 0.5884 - accuracy: 0.7979 - val_loss: 0.7278 - val_accuracy: 0.7724\n",
      "Epoch 15/40\n",
      "40000/40000 [==============================] - 149s 4ms/step - loss: 0.5850 - accuracy: 0.8001 - val_loss: 0.7608 - val_accuracy: 0.7554\n",
      "Epoch 16/40\n",
      "40000/40000 [==============================] - 149s 4ms/step - loss: 0.5767 - accuracy: 0.8059 - val_loss: 0.7300 - val_accuracy: 0.7750\n",
      "Epoch 17/40\n",
      "40000/40000 [==============================] - 148s 4ms/step - loss: 0.5668 - accuracy: 0.8101 - val_loss: 0.8043 - val_accuracy: 0.7352\n",
      "Epoch 18/40\n",
      "40000/40000 [==============================] - 146s 4ms/step - loss: 0.5642 - accuracy: 0.8108 - val_loss: 0.6539 - val_accuracy: 0.7892\n",
      "Epoch 19/40\n",
      "40000/40000 [==============================] - 148s 4ms/step - loss: 0.5640 - accuracy: 0.8124 - val_loss: 1.0263 - val_accuracy: 0.7514\n",
      "Epoch 20/40\n",
      "40000/40000 [==============================] - 148s 4ms/step - loss: 0.5533 - accuracy: 0.8149 - val_loss: 1.0855 - val_accuracy: 0.7257\n",
      "Epoch 21/40\n",
      "40000/40000 [==============================] - 149s 4ms/step - loss: 0.5524 - accuracy: 0.8139 - val_loss: 0.7252 - val_accuracy: 0.7838\n",
      "Epoch 22/40\n",
      "40000/40000 [==============================] - 150s 4ms/step - loss: 0.5533 - accuracy: 0.8166 - val_loss: 0.8228 - val_accuracy: 0.7764\n",
      "Epoch 23/40\n",
      "40000/40000 [==============================] - 147s 4ms/step - loss: 0.5464 - accuracy: 0.8213 - val_loss: 0.7196 - val_accuracy: 0.7826\n",
      "Epoch 24/40\n",
      "40000/40000 [==============================] - 149s 4ms/step - loss: 0.5427 - accuracy: 0.8228 - val_loss: 0.7470 - val_accuracy: 0.7629\n",
      "Epoch 25/40\n",
      "40000/40000 [==============================] - 147s 4ms/step - loss: 0.5471 - accuracy: 0.8194 - val_loss: 0.9236 - val_accuracy: 0.7651\n",
      "Epoch 26/40\n",
      "40000/40000 [==============================] - 147s 4ms/step - loss: 0.5457 - accuracy: 0.8204 - val_loss: 0.6737 - val_accuracy: 0.7769\n",
      "Epoch 27/40\n",
      "40000/40000 [==============================] - 149s 4ms/step - loss: 0.5426 - accuracy: 0.8222 - val_loss: 0.7928 - val_accuracy: 0.7697\n",
      "Epoch 28/40\n",
      "40000/40000 [==============================] - 150s 4ms/step - loss: 0.5441 - accuracy: 0.8230 - val_loss: 0.8238 - val_accuracy: 0.7659\n",
      "Epoch 29/40\n",
      "40000/40000 [==============================] - 156s 4ms/step - loss: 0.5476 - accuracy: 0.8219 - val_loss: 0.7688 - val_accuracy: 0.7775\n",
      "Epoch 30/40\n",
      "40000/40000 [==============================] - 156s 4ms/step - loss: 0.5419 - accuracy: 0.8217 - val_loss: 0.7401 - val_accuracy: 0.7881\n",
      "Epoch 31/40\n",
      "40000/40000 [==============================] - 149s 4ms/step - loss: 0.5509 - accuracy: 0.8199 - val_loss: 0.7397 - val_accuracy: 0.7620\n",
      "Epoch 32/40\n",
      "40000/40000 [==============================] - 150s 4ms/step - loss: 0.5519 - accuracy: 0.8228 - val_loss: 0.7596 - val_accuracy: 0.7565\n",
      "Epoch 33/40\n",
      "40000/40000 [==============================] - 139s 3ms/step - loss: 0.5474 - accuracy: 0.8236 - val_loss: 0.8468 - val_accuracy: 0.7883\n",
      "Epoch 34/40\n",
      "40000/40000 [==============================] - 97s 2ms/step - loss: 0.5438 - accuracy: 0.8240 - val_loss: 1.1565 - val_accuracy: 0.7538\n",
      "Epoch 35/40\n",
      "40000/40000 [==============================] - 95s 2ms/step - loss: 0.5574 - accuracy: 0.8243 - val_loss: 0.7543 - val_accuracy: 0.7913\n",
      "Epoch 36/40\n",
      "40000/40000 [==============================] - 96s 2ms/step - loss: 0.5523 - accuracy: 0.8220 - val_loss: 0.6918 - val_accuracy: 0.7802\n",
      "Epoch 37/40\n",
      "40000/40000 [==============================] - 95s 2ms/step - loss: 0.5553 - accuracy: 0.8213 - val_loss: 0.6931 - val_accuracy: 0.7719\n",
      "Epoch 38/40\n",
      "40000/40000 [==============================] - 93s 2ms/step - loss: 0.5621 - accuracy: 0.8203 - val_loss: 0.6733 - val_accuracy: 0.7838\n",
      "Epoch 39/40\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.5578 - accuracy: 0.8199 - val_loss: 0.6918 - val_accuracy: 0.7915\n",
      "Epoch 40/40\n",
      "40000/40000 [==============================] - 93s 2ms/step - loss: 0.5583 - accuracy: 0.8213 - val_loss: 0.6794 - val_accuracy: 0.7912\n",
      "10000/10000 [==============================] - 9s 881us/step\n",
      "Test score: 0.7287246189117431\n",
      "Test accuracy: 0.7750999927520752\n"
     ]
    }
   ],
   "source": [
    "# deeper network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# dump the network and change iterations\n",
    "model.summary()\n",
    "NB_EPOCH = 40\n",
    "\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "# And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting training set images...\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,676,842\n",
      "Trainable params: 1,676,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=50, verbose=1, steps_per_epoch=390)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "390/390 [==============================] - 108s 276ms/step - loss: 4.6545 - accuracy: 0.1037\n",
      "Epoch 2/50\n",
      "390/390 [==============================] - 108s 278ms/step - loss: 2.3065 - accuracy: 0.0994\n",
      "Epoch 3/50\n",
      "390/390 [==============================] - 108s 277ms/step - loss: 2.3054 - accuracy: 0.0982\n",
      "Epoch 4/50\n",
      "390/390 [==============================] - 107s 275ms/step - loss: 2.3068 - accuracy: 0.0978\n",
      "Epoch 5/50\n",
      "390/390 [==============================] - 108s 276ms/step - loss: 2.3043 - accuracy: 0.0988\n",
      "Epoch 6/50\n",
      "390/390 [==============================] - 107s 274ms/step - loss: 2.3075 - accuracy: 0.0967\n",
      "Epoch 7/50\n",
      "390/390 [==============================] - 107s 274ms/step - loss: 2.3038 - accuracy: 0.0991\n",
      "Epoch 8/50\n",
      "390/390 [==============================] - 108s 276ms/step - loss: 2.3041 - accuracy: 0.0988\n",
      "Epoch 9/50\n",
      "390/390 [==============================] - 108s 277ms/step - loss: 2.3063 - accuracy: 0.0985\n",
      "Epoch 10/50\n",
      "390/390 [==============================] - 107s 275ms/step - loss: 2.3044 - accuracy: 0.0982\n",
      "Epoch 11/50\n",
      "390/390 [==============================] - 107s 275ms/step - loss: 2.3027 - accuracy: 0.0973\n",
      "Epoch 12/50\n",
      "390/390 [==============================] - 107s 275ms/step - loss: 2.3041 - accuracy: 0.0984\n",
      "Epoch 13/50\n",
      "390/390 [==============================] - 108s 276ms/step - loss: 2.3061 - accuracy: 0.0989\n",
      "Epoch 14/50\n",
      "390/390 [==============================] - 108s 276ms/step - loss: 2.3028 - accuracy: 0.0975\n",
      "Epoch 15/50\n",
      "390/390 [==============================] - 107s 275ms/step - loss: 2.3044 - accuracy: 0.0968\n",
      "Epoch 16/50\n",
      "390/390 [==============================] - 108s 276ms/step - loss: 2.3032 - accuracy: 0.0989\n",
      "Epoch 17/50\n",
      "390/390 [==============================] - 107s 275ms/step - loss: 2.3028 - accuracy: 0.0981\n",
      "Epoch 18/50\n",
      "390/390 [==============================] - 108s 276ms/step - loss: 2.3041 - accuracy: 0.0980\n",
      "Epoch 19/50\n",
      "390/390 [==============================] - 107s 275ms/step - loss: 2.3029 - accuracy: 0.0990\n",
      "Epoch 20/50\n",
      "390/390 [==============================] - 112s 288ms/step - loss: 2.3035 - accuracy: 0.0981\n",
      "Epoch 21/50\n",
      "390/390 [==============================] - 113s 289ms/step - loss: 2.3044 - accuracy: 0.0992\n",
      "Epoch 22/50\n",
      "390/390 [==============================] - 108s 276ms/step - loss: 2.3031 - accuracy: 0.0976\n",
      "Epoch 23/50\n",
      "390/390 [==============================] - 107s 275ms/step - loss: 2.3029 - accuracy: 0.0982\n",
      "Epoch 24/50\n",
      "390/390 [==============================] - 107s 276ms/step - loss: 2.3031 - accuracy: 0.0986\n",
      "Epoch 25/50\n",
      "390/390 [==============================] - 108s 276ms/step - loss: 2.3032 - accuracy: 0.0968\n",
      "Epoch 26/50\n",
      "390/390 [==============================] - 107s 275ms/step - loss: 2.3062 - accuracy: 0.0992\n",
      "Epoch 27/50\n",
      "390/390 [==============================] - 108s 276ms/step - loss: 2.3028 - accuracy: 0.0983\n",
      "Epoch 28/50\n",
      "390/390 [==============================] - 108s 277ms/step - loss: 2.3027 - accuracy: 0.0963\n",
      "Epoch 29/50\n",
      "390/390 [==============================] - 107s 274ms/step - loss: 2.3029 - accuracy: 0.0975\n",
      "Epoch 30/50\n",
      "390/390 [==============================] - 107s 274ms/step - loss: 2.3026 - accuracy: 0.0982\n",
      "Epoch 31/50\n",
      "390/390 [==============================] - 107s 274ms/step - loss: 2.3032 - accuracy: 0.0993\n",
      "Epoch 32/50\n",
      "390/390 [==============================] - 107s 275ms/step - loss: 2.3027 - accuracy: 0.0967\n",
      "Epoch 33/50\n",
      "390/390 [==============================] - 107s 276ms/step - loss: 2.3030 - accuracy: 0.0964\n",
      "Epoch 34/50\n",
      "390/390 [==============================] - 107s 274ms/step - loss: 2.3029 - accuracy: 0.0987\n",
      "Epoch 35/50\n",
      "390/390 [==============================] - 107s 275ms/step - loss: 2.3065 - accuracy: 0.0979\n",
      "Epoch 36/50\n",
      "390/390 [==============================] - 107s 274ms/step - loss: 2.3027 - accuracy: 0.0976\n",
      "Epoch 37/50\n",
      "390/390 [==============================] - 107s 274ms/step - loss: 2.3040 - accuracy: 0.0992\n",
      "Epoch 38/50\n",
      "390/390 [==============================] - 108s 276ms/step - loss: 2.3027 - accuracy: 0.0951\n",
      "Epoch 39/50\n",
      "390/390 [==============================] - 107s 274ms/step - loss: 2.3027 - accuracy: 0.0977\n",
      "Epoch 40/50\n",
      "390/390 [==============================] - 107s 274ms/step - loss: 2.3030 - accuracy: 0.0984\n",
      "Epoch 41/50\n",
      "390/390 [==============================] - 107s 274ms/step - loss: 2.3027 - accuracy: 0.0969\n",
      "Epoch 42/50\n",
      "390/390 [==============================] - 107s 275ms/step - loss: 2.3027 - accuracy: 0.0995\n",
      "Epoch 43/50\n",
      "390/390 [==============================] - 108s 276ms/step - loss: 2.3027 - accuracy: 0.0974\n",
      "Epoch 44/50\n",
      "390/390 [==============================] - 107s 275ms/step - loss: 2.3027 - accuracy: 0.0971\n",
      "Epoch 45/50\n",
      "390/390 [==============================] - 108s 276ms/step - loss: 2.3027 - accuracy: 0.0986\n",
      "Epoch 46/50\n",
      "390/390 [==============================] - 108s 278ms/step - loss: 2.3027 - accuracy: 0.0958\n",
      "Epoch 47/50\n",
      "390/390 [==============================] - 108s 276ms/step - loss: 2.3026 - accuracy: 0.0970\n",
      "Epoch 48/50\n",
      "390/390 [==============================] - 108s 276ms/step - loss: 2.3027 - accuracy: 0.0967\n",
      "Epoch 49/50\n",
      "390/390 [==============================] - 105s 270ms/step - loss: 2.3027 - accuracy: 0.0983\n",
      "Epoch 50/50\n",
      "390/390 [==============================] - 108s 276ms/step - loss: 2.3044 - accuracy: 0.0975\n",
      "10000/10000 [==============================] - 9s 871us/step\n",
      "Test score: 2.302604217529297\n",
      "Test accuracy: 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "# data augmentation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "NUM_TO_AUGMENT=5\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# augumenting\n",
    "print(\"Augmenting training set images...\")\n",
    "datagen = ImageDataGenerator(rotation_range=40,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "xtas, ytas = [], []\n",
    "for i in range(X_train.shape[0]):\n",
    "    num_aug = 0\n",
    "    x = X_train[i] # (3, 32, 32)\n",
    "    x = x.reshape((1,) + x.shape) # (1, 3, 32, 32)\n",
    "for x_aug in datagen.flow(x, batch_size=1,\n",
    "                save_to_dir='preview',\n",
    "                save_prefix='cifar',\n",
    "                save_format='jpeg'):\n",
    "    if num_aug >= NUM_TO_AUGMENT:\n",
    "        break\n",
    "    xtas.append(x_aug[0])\n",
    "    num_aug += 1\n",
    "\n",
    "#fit the dataget\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# dump the network and change iterations\n",
    "model.summary()\n",
    "NB_EPOCH = 50\n",
    "\n",
    "# train\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "            batch_size=BATCH_SIZE), samples_per_epoch=X_train.shape[0],\n",
    "            epochs=NB_EPOCH, verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "            batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain how this algorithm could result in ethical and privacy concerns if it were trained on different sets of images.\n",
    "\n",
    "Facial recognition technology is used in all areas.  Cell phones, medical diagnosis, and even law enforcement.  Using someone's image should require informed consent.  Unfortunately, this is not always the case.  The ring doorbell, owned by Amazon, can be given to police without a user's consent.  If a person's image is used to train an algorithm, or identified through an algorithm, this could lead to other concerns.  “For example, if you use facial recognition to identify people coming into a store, should you use that identity to pull purchasing history?” (Gray, 2022).\n",
    "There’s also the issue of bias within race. A 2018 study performed by MIT found that most algorithms misidentified darker-skinned women (Gray, 2022).  Data put into the algorithm needs to be as diverse as possible.  This may be difficult to achieve if the development team isn’t diverse.\n",
    "\n",
    "References:\n",
    "\n",
    "Gray, P. (2022, August 31). Ethical issues of Facial Recognition Technology. TechRepublic. Retrieved March 15, 2023, from https://www.techrepublic.com/article/ethical-issues-facial-recognition/ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
